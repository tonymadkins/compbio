{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of splicing dataset = 10000\n"
     ]
    }
   ],
   "source": [
    "#Read splicing data\n",
    "\n",
    "df = pd.read_csv('Splicing_Data.txt', sep='\\t')\n",
    "df = df.loc[~np.isnan(df.SD1_Usage)].copy().reset_index(drop=True)\n",
    "\n",
    "df = df.iloc[-10000:].copy().reset_index(drop=True)\n",
    "\n",
    "df['Region1'] = df['Seqs'].str.slice(2, 37)\n",
    "\n",
    "print('Size of splicing dataset = ' + str(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 6-mer features from sequence 0\n",
      "Extracting 6-mer features from sequence 2000\n",
      "Extracting 6-mer features from sequence 4000\n",
      "Extracting 6-mer features from sequence 6000\n",
      "Extracting 6-mer features from sequence 8000\n",
      "Shape of X = (10000, 4096)\n",
      "Shape of y = (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Generate 6mer feature matrix\n",
    "\n",
    "mer6_dict = {}\n",
    "mer6_list = []\n",
    "bases = list('ACGT')\n",
    "\n",
    "#Build dictionary of 6-mer -> index\n",
    "i = 0\n",
    "for b1 in bases :\n",
    "    for b2 in bases :\n",
    "        for b3 in bases :\n",
    "            for b4 in bases :\n",
    "                for b5 in bases :\n",
    "                    for b6 in bases :\n",
    "                        mer6_dict[b1 + b2 + b3 + b4 + b5 + b6] = i\n",
    "                        mer6_list.append(b1 + b2 + b3 + b4 + b5 + b6)\n",
    "                        i += 1\n",
    "\n",
    "#Loop over dataframe, fill matrix X with 6-mer counts\n",
    "X = sp.lil_matrix((len(df), len(mer6_dict)))\n",
    "for index, row in df.iterrows() :\n",
    "    if index % 2000 == 0 :\n",
    "        print('Extracting 6-mer features from sequence ' + str(index))\n",
    "    \n",
    "    region1 = row['Region1']\n",
    "    #Loop over all 6-mers in the current sequence\n",
    "    for j in range(0, len(region1) - 6 + 1) :\n",
    "        if region1[j:j+6] in mer6_dict :\n",
    "            #Increment X at the corrposnding 6-mer index position\n",
    "            X[index, mer6_dict[region1[j:j+6]]] += 1.\n",
    "\n",
    "X = sp.csr_matrix(X)\n",
    "y = np.ravel(df['SD1_Usage'].values)\n",
    "\n",
    "print('Shape of X = ' + str(X.shape))\n",
    "print('Shape of y = ' + str(y.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1.1\n",
    "#TODO: Calculate log odds ratios of 6-mers using feature matrix X and splicing ratios y\n",
    "\n",
    "X_col = sp.csc_matrix(X) #More efficient representation of X when working with columns\n",
    "\n",
    "logodds_ratios = np.zeros(X_col.shape[1])\n",
    "\n",
    "#Loop over every 6-mer index\n",
    "for w_i in range(logodds_ratios.shape[0]) :\n",
    "    if w_i % 1000 == 0 :\n",
    "        print('Calculating logodds for 6-mer ' + str(w_i) + '...')\n",
    "    \n",
    "    #TODO: Calculate and store the log odds ratio of each 6-mer in vector 'logodds_ratios'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1.1\n",
    "#TODO: Plot the sorted Log odds ratios, and print the smallest and largest values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1.3\n",
    "#TODO: Split data (matrix X and vector y) into training and test sets. Test set should contain 2,000 data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1.3\n",
    "#TODO: Implement Gradient Descent with KL-divergence gradients for regressing splice site usages\n",
    "\n",
    "#Helper function for computing log(x / y) in a safe way (whenever x or y is 0).\n",
    "def safe_kl_log(num, denom) :\n",
    "    log_vec = np.zeros(num.shape)\n",
    "    log_vec[(num > 0) & (denom > 0)] = np.log(num[(num > 0) & (denom > 0)] / denom[(num > 0) & (denom > 0)])\n",
    "    \n",
    "    return log_vec\n",
    "\n",
    "#Compute the KL divergence loss (alpha is regularization parameter)\n",
    "def kl_divergence_loss(X, w, w_0, y_true, alpha=0.0001) :\n",
    "    #TODO: Implement and return kl divergence loss function\n",
    "    \n",
    "    return 0\n",
    "\n",
    "#Compute the KL divergence gradients for the weight vector w and intercept term w_0 (alpha is regularization parameter)\n",
    "def kl_divergence_gradients(X, w, w_0, y_true, alpha=0.0001) :\n",
    "    #TODO: Implement and return kl divergence loss gradients for w and w_0\n",
    "    \n",
    "    return np.zeros(w.shape), 0\n",
    "\n",
    "#Gradient Descent algorithm to optimize weights w and w_0\n",
    "def gradient_descent(X_train, y_train, X_test, y_test, w, w_0, step_size=0.1, alpha=0.0001, max_epochs=2000) :\n",
    "    \n",
    "    mean_train_losses = []\n",
    "    mean_test_losses = []\n",
    "    for epoch in range(max_epochs) : #Stop after unreasonable # of iterations, in case we never converge\n",
    "        if epoch % 50 == 1 and len(mean_train_losses) > 0 :\n",
    "            print('Training epoch = ' + str(epoch))\n",
    "            print('Training set KL-div = ' + str(round(mean_train_losses[-1], 4)))\n",
    "            print('Test set KL-div = ' + str(round(mean_test_losses[-1], 4)))\n",
    "        \n",
    "        #TODO: Calculate the KL loss and gradients on the training set\n",
    "        #Update your weights w and w_0 based on the gradients\n",
    "        #Append your mean train and test loss to 'mean_train_losses' and 'mean_test_losses'\n",
    "        \n",
    "        \n",
    "        #TODO: Stop the loop once the training loss stops decreasing significantly\n",
    "    \n",
    "    \n",
    "    print('Gradient descent completed.')\n",
    "    print('Final training set KL-div = ' + str(round(mean_train_losses[-1], 4)))\n",
    "    print('Final test set KL-div = ' + str(round(mean_test_losses[-1], 4)))\n",
    "    \n",
    "    return w, w_0, mean_train_losses, mean_test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Problem 1.3\n",
    "#Here we initialize the weight vector and intercept term to zeros.\n",
    "w, w_0 = np.zeros(X.shape[1]), 0\n",
    "\n",
    "#Train the weights using your Gradient Descent algorithm\n",
    "w, w_0, train_losses, test_losses = gradient_descent(X_train, y_train, X_test, y_test, w, w_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1.3\n",
    "#TODO: Plot training and test set loss (mean KL-div) vs. training iteration\n",
    "\n",
    "#TODO: Scatter plot of true vs. pred SD1 usage on test set, and print R^2 coefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1.3\n",
    "#TODO: Plot the 10 6-mers and corresponding weights of largest magnitude\n",
    "#TODO: Plot the 10 6-mers and corresponding weights of smallest magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
